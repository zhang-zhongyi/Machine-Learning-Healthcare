{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh13920\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 from sklearn.linear_model import LogisticRegression\
seed(0)\
params0 = \{'tol' : [1e-6,1e-5,1e-4,1e-3,1e-2],\
           'C': [0.5,1.0,1.5,2.0,2.5]\}\
lg = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\
lg = GridSearchCV(lg, cv=5, param_grid=params0, scoring = 'roc_auc',refit = True, \
                  n_jobs=-1, verbose = 5, return_train_score=True)\
\
lg.fit(X_train, y_train)\
lg.cv_results_\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
lg.best_estimator_\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
lg_pred = lg.best_estimator_.predict(X_test)\
lg_prob = lg.best_estimator_.predict_proba(X_test) \
lg_prob\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
lg_matrix = metrics.confusion_matrix(y_test, lg_pred)\
lg_matrix\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
lg_test = lg.best_estimator_.score(X_test, y_test)\
\
lg_matrix = metrics.confusion_matrix(y_test, lg_pred)\
\
lg_cm = pd.DataFrame(lg_matrix, range(2), range(2))\
# plt.figure(figsize=(5, 8))\
fig, ax = plt.subplots(figsize=(6,4))\
akws = \{"ha": 'center',"va": 'center','c':'black','fontsize':'20'\}\
ax = sns.heatmap (lg_cm, fmt='d',\
                  cmap='Oranges_r', annot=True, square = True,ax=ax,linewidths=0.5,annot_kws=akws)\
bottom, top = ax.get_ylim()\
ax.set_ylim(bottom + 0.5, top - 0.5)\
\
plt.xlabel('Predicted Class')\
plt.ylabel('Actual Class')\
\
lg_title = 'Logistic Regression - Confussion Matrix on Test Data \\nMean Accuracy Score: \{0:2f\}'.format(lg_test)\
plt.title(lg_title, size = 14)\
# plt.figure(figsize=(16, 26))\
plt.show;\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
print("", classification_report(y_test, lg_pred, target_names=target_names))\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
acc_lg = accuracy_score(y_test, lg_pred)\
print("Logistic Regression accuracy:", acc_lg)\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
error_lg = 1-acc_lg\
error_lg\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
lg_probs = lg.best_estimator_.predict_proba(X_test)[:,1]\
print(roc_auc_score(y_test, lg_probs))\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
### For training set:\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
lg_pred_tr = lg.best_estimator_.predict(X_train)\
lg_prob_tr = lg.best_estimator_.predict_proba(X_train) \
lg_prob_tr\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
lg_matrix_tr = metrics.confusion_matrix(y_train, lg_pred_tr)\
lg_matrix_tr\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
lg_train = lg.best_estimator_.score(X_train, y_train)\
\
lg_matrix = metrics.confusion_matrix(y_train, lg_pred_tr)\
\
lg_cm_tr = pd.DataFrame(lg_matrix, range(2), range(2))\
\
fig, ax = plt.subplots(figsize=(6,4))\
akws = \{"ha": 'center',"va": 'center','c':'red','fontsize':'20'\}\
ax = sns.heatmap (lg_cm_tr, fmt='d',\
                  cmap='Blues_r', annot=True, square = True,ax=ax,linewidths=0.5,annot_kws=akws)\
bottom, top = ax.get_ylim()\
ax.set_ylim(bottom + 0.5, top - 0.5)\
\
plt.xlabel('Predicted Class')\
plt.ylabel('Actual Class')\
\
lg_title = 'Logistic Regression - Confussion Matrix on Train Data \\nMean Accuracy Score: \{0:2f\}'.format(lg_train)\
plt.title(lg_title, size = 14)\
# plt.figure(figsize=(16, 26))\
plt.show;\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
print("", classification_report(y_train, lg_pred_tr, target_names=target_names))\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
y_pred = lg_probs\
y_true = y_test_v\
\
print("Original ROC area: \{:0.4f\}".format(roc_auc_score(y_true, y_pred)))\
\
n_bootstraps = 1000\
rng_seed = 42  # control reproducibility\
bootstrapped_scores = []\
\
rng = np.random.RandomState(rng_seed)\
for i in range(n_bootstraps):\
    # bootstrap by sampling with replacement on the prediction indices\
    indices = rng.randint(0, len(y_pred), len(y_pred))\
    if len(np.unique(y_true[indices])) < 2:\
        # We need at least one positive and one negative sample for ROC AUC\
        # to be defined: reject the sample\
        continue\
\
    score = roc_auc_score(y_true[indices], y_pred[indices])\
    bootstrapped_scores.append(score)\
    #print("Bootstrap #\{\} ROC area: \{:0.3f\}".format(i + 1, score))\
    \
import matplotlib.pyplot as plt\
plt.hist(bootstrapped_scores, bins=50)\
plt.title('Histogram of the bootstrapped ROC AUC scores')\
plt.show()\
\
sorted_scores = np.array(bootstrapped_scores)\
sorted_scores.sort()\
\
# Computing the lower and upper bound of the 90% confidence interval\
# You can change the bounds percentiles to 0.025 and 0.975 to get\
# a 95% confidence interval instead.\
confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\
confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\
print("Confidence interval for the score: [\{:0.4f\} - \{:0.4\}]".format(\
    confidence_lower, confidence_upper))\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
alpha = .95\
y_pred = lg_probs\
y_true = y_test_v2\
\
auc, auc_cov = delong_roc_variance(\
    y_true,\
    y_pred)\
\
auc_std = np.sqrt(auc_cov)\
lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\
\
ci = stats.norm.ppf(\
    lower_upper_q,\
    loc=auc,\
    scale=auc_std)\
\
ci[ci > 1] = 1\
\
print('AUC:', auc)\
print('AUC COV:', auc_cov)\
print('95% AUC CI:', ci)\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
print(dt.best_estimator_.feature_importances_)\
pyplot.bar(range(len(dt.best_estimator_.feature_importances_)), dt.best_estimator_.feature_importances_)\
pyplot.show()\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\
feat_importances_dt = pd.Series(dt.best_estimator_.feature_importances_, index=X_train.columns)\
feat_importances_dt.nlargest(5).plot(kind='barh')\
pyplot.show()}